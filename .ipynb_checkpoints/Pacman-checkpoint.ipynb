{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 150.0\n",
      "Total Score: 340.0\n",
      "Total Score: 110.0\n",
      "Total Score: 260.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 130.0\n",
      "Total Score: 350.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 270.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 290.0\n",
      "Total Score: 220.0\n",
      "Total Score: 270.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 290.0\n",
      "Total Score: 240.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 280.0\n",
      "Total Score: 120.0\n",
      "Total Score: 180.0\n",
      "Total Score: 140.0\n",
      "Total Score: 150.0\n",
      "Total Score: 210.0\n",
      "Total Score: 120.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 310.0\n",
      "Total Score: 410.0\n",
      "Total Score: 280.0\n",
      "Total Score: 120.0\n",
      "Total Score: 200.0\n",
      "Total Score: 140.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 340.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 300.0\n",
      "Total Score: 190.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 270.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n",
      "Total Score: 230.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 200.0\n",
      "Total Score: 170.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 140.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 410.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 410.0\n",
      "Total Score: 220.0\n",
      "Total Score: 110.0\n",
      "Total Score: 330.0\n",
      "Total Score: 260.0\n",
      "Total Score: 90.0\n",
      "Total Score: 260.0\n",
      "Total Score: 290.0\n",
      "Total Score: 170.0\n",
      "Total Score: 120.0\n",
      "Total Score: 290.0\n",
      "Total Score: 210.0\n",
      "Total Score: 130.0\n",
      "Total Score: 140.0\n",
      "Total Score: 220.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 350.0\n",
      "Total Score: 190.0\n",
      "Total Score: 280.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 180.0\n",
      "Total Score: 270.0\n",
      "Total Score: 100.0\n",
      "Total Score: 160.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 350.0\n",
      "Total Score: 100.0\n",
      "Total Score: 330.0\n",
      "Total Score: 160.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 160.0\n",
      "Total Score: 100.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 240.0\n",
      "Total Score: 300.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 110.0\n",
      "Total Score: 110.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 130.0\n",
      "Total Score: 190.0\n",
      "Total Score: 160.0\n",
      "Total Score: 230.0\n",
      "Total Score: 130.0\n",
      "Total Score: 260.0\n",
      "Total Score: 280.0\n",
      "Total Score: 110.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 260.0\n",
      "Total Score: 150.0\n",
      "Total Score: 400.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 250.0\n",
      "Total Score: 320.0\n",
      "Total Score: 370.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 270.0\n",
      "Total Score: 410.0\n",
      "Total Score: 250.0\n",
      "Total Score: 170.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 140.0\n",
      "Total Score: 140.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 350.0\n",
      "Total Score: 170.0\n",
      "Total Score: 190.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 170.0\n",
      "Total Score: 290.0\n",
      "Total Score: 540.0\n",
      "Total Score: 290.0\n",
      "Total Score: 310.0\n",
      "Total Score: 280.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 270.0\n",
      "Total Score: 340.0\n",
      "Total Score: 230.0\n",
      "Total Score: 110.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 270.0\n",
      "Total Score: 320.0\n",
      "Total Score: 140.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 290.0\n",
      "Total Score: 420.0\n",
      "Total Score: 130.0\n",
      "Total Score: 170.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 340.0\n",
      "Total Score: 190.0\n",
      "Total Score: 110.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 120.0\n",
      "Total Score: 230.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 350.0\n",
      "Total Score: 200.0\n",
      "Total Score: 150.0\n",
      "Total Score: 160.0\n",
      "Total Score: 110.0\n",
      "Total Score: 280.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 140.0\n",
      "Total Score: 280.0\n",
      "Total Score: 300.0\n",
      "Total Score: 190.0\n",
      "Total Score: 230.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 110.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 240.0\n",
      "Total Score: 130.0\n",
      "Total Score: 220.0\n",
      "Total Score: 300.0\n",
      "Total Score: 270.0\n",
      "Total Score: 290.0\n",
      "Total Score: 160.0\n",
      "Total Score: 130.0\n",
      "Total Score: 220.0\n",
      "Total Score: 150.0\n",
      "Total Score: 300.0\n",
      "Total Score: 160.0\n",
      "Total Score: 300.0\n",
      "Total Score: 160.0\n",
      "Total Score: 260.0\n",
      "Total Score: 970.0\n",
      "Total Score: 270.0\n",
      "Total Score: 100.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 200.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 150.0\n",
      "Total Score: 130.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 610.0\n",
      "Total Score: 230.0\n",
      "Total Score: 150.0\n",
      "Total Score: 110.0\n",
      "Total Score: 160.0\n",
      "Total Score: 150.0\n",
      "Total Score: 200.0\n",
      "Total Score: 260.0\n",
      "Total Score: 200.0\n",
      "Total Score: 220.0\n",
      "Total Score: 220.0\n",
      "Total Score: 260.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 170.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 240.0\n",
      "Total Score: 150.0\n",
      "Total Score: 260.0\n",
      "Total Score: 260.0\n",
      "Total Score: 200.0\n",
      "Total Score: 270.0\n",
      "Total Score: 250.0\n",
      "Total Score: 150.0\n",
      "Total Score: 290.0\n",
      "Total Score: 130.0\n",
      "Total Score: 200.0\n",
      "Total Score: 130.0\n",
      "Total Score: 190.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 150.0\n",
      "Total Score: 310.0\n",
      "Total Score: 240.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 140.0\n",
      "Total Score: 150.0\n",
      "Total Score: 320.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 290.0\n",
      "Total Score: 110.0\n",
      "Total Score: 160.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 230.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 140.0\n",
      "Total Score: 240.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 110.0\n",
      "Total Score: 270.0\n",
      "Total Score: 220.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 150.0\n",
      "Total Score: 180.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 230.0\n",
      "Total Score: 290.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 170.0\n",
      "Total Score: 340.0\n",
      "Total Score: 200.0\n",
      "Total Score: 140.0\n",
      "Total Score: 250.0\n",
      "Total Score: 70.0\n",
      "Total Score: 150.0\n",
      "Total Score: 130.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 150.0\n",
      "Total Score: 200.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 240.0\n",
      "Total Score: 170.0\n",
      "Total Score: 270.0\n",
      "Total Score: 320.0\n",
      "Total Score: 210.0\n",
      "Total Score: 110.0\n",
      "Total Score: 240.0\n",
      "Total Score: 580.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 210.0\n",
      "Total Score: 160.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 380.0\n",
      "Total Score: 200.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 160.0\n",
      "Total Score: 190.0\n",
      "Total Score: 140.0\n",
      "Total Score: 300.0\n",
      "Total Score: 230.0\n",
      "Total Score: 160.0\n",
      "Total Score: 270.0\n",
      "Total Score: 120.0\n",
      "Total Score: 340.0\n",
      "Total Score: 190.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n",
      "Total Score: 260.0\n",
      "Total Score: 290.0\n",
      "Total Score: 230.0\n",
      "Total Score: 250.0\n",
      "Total Score: 290.0\n",
      "Total Score: 170.0\n",
      "Total Score: 290.0\n",
      "Total Score: 100.0\n",
      "Total Score: 330.0\n",
      "Total Score: 240.0\n",
      "Total Score: 270.0\n",
      "Total Score: 190.0\n",
      "Total Score: 150.0\n",
      "Total Score: 320.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 240.0\n",
      "Total Score: 230.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 320.0\n",
      "Total Score: 320.0\n",
      "Total Score: 280.0\n",
      "Total Score: 240.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 60.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 310.0\n",
      "Total Score: 180.0\n",
      "Total Score: 280.0\n",
      "Total Score: 210.0\n",
      "Total Score: 310.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Average Score for 500 Episodes: 214.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import wrappers, logger\n",
    "\n",
    "\n",
    "EPISODES = 500\n",
    "ALL_SCORES = np.zeros(EPISODES)\n",
    "\n",
    "env = gym.make(\"MsPacman-ram-v0\")\n",
    "env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    env.reset()\n",
    "    \n",
    "    reward, info, done = None, None, None\n",
    "\n",
    "    \n",
    "    total_score = 0\n",
    "    while done != True:\n",
    "        # env.render()\n",
    "        random_action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(random_action)\n",
    "        total_score += reward\n",
    "    ALL_SCORES[episode] = total_score\n",
    "    print(\"Total Score: {}\".format(total_score))\n",
    "    # print(state, reward, done, info)\n",
    "    \n",
    "env.close()\n",
    "plt.plot(ALL_SCORES)\n",
    "plt.title(\"Random Agent: {} Episodes\".format(EPISODES))\n",
    "plt.show()\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print('Average Score for {} Episodes: {}'.format(EPISODES, np.mean(ALL_SCORES)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2- corrected reward (0.01 LR, batch size 256, min epsilon 0.05, episilon decay 0.9999)  \n",
    "v2- corrected reward (0.05 LR, batch size 256, min epsilon 0.0, episilon decay 0.99999), increased memeory from 2000 to 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 25,353\n",
      "Trainable params: 25,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 230.0   memory length: 666   epsilon: 0.9933620955680029\n",
      "episode: 1   score: 170.0   memory length: 1326   epsilon: 0.9868274610786957\n",
      "episode: 2   score: 250.0   memory length: 2020   epsilon: 0.9800025541939262\n",
      "episode: 3   score: 470.0   memory length: 2910   epsilon: 0.9713191863493108\n",
      "episode: 4   score: 230.0   memory length: 3515   epsilon: 0.9654604166269837\n",
      "episode: 5   score: 170.0   memory length: 4037   epsilon: 0.9604338189530586\n",
      "episode: 6   score: 230.0   memory length: 4689   epsilon: 0.9541921292648833\n",
      "episode: 7   score: 250.0   memory length: 5392   epsilon: 0.9475076486526106\n",
      "episode: 8   score: 290.0   memory length: 6095   epsilon: 0.9408699953822174\n",
      "episode: 9   score: 230.0   memory length: 6738   epsilon: 0.9348395797234842\n",
      "episode: 10   score: 200.0   memory length: 7403   epsilon: 0.9286434903689332\n",
      "episode: 11   score: 170.0   memory length: 7953   epsilon: 0.9235499457917841\n",
      "episode: 12   score: 3430.0   memory length: 9013   epsilon: 0.9138119701276923\n",
      "episode: 13   score: 260.0   memory length: 9702   epsilon: 0.9075374149456124\n",
      "episode: 14   score: 120.0   memory length: 10000   epsilon: 0.9023159762911498\n",
      "episode: 15   score: 60.0   memory length: 10000   epsilon: 0.8993432264406652\n",
      "episode: 16   score: 180.0   memory length: 10000   epsilon: 0.8946161308392168\n",
      "episode: 17   score: 240.0   memory length: 10000   epsilon: 0.8881535866081313\n",
      "episode: 18   score: 140.0   memory length: 10000   epsilon: 0.8830966556216782\n",
      "episode: 19   score: 370.0   memory length: 10000   epsilon: 0.8763929989565404\n",
      "episode: 20   score: 100.0   memory length: 10000   epsilon: 0.8732087114380677\n",
      "episode: 21   score: 200.0   memory length: 10000   epsilon: 0.8671088927153048\n",
      "episode: 22   score: 290.0   memory length: 10000   epsilon: 0.8601222459315958\n",
      "episode: 23   score: 120.0   memory length: 10000   epsilon: 0.8552933396687521\n",
      "episode: 24   score: 190.0   memory length: 10000   epsilon: 0.8494036057091799\n",
      "episode: 25   score: 200.0   memory length: 10000   epsilon: 0.8436050447621647\n",
      "episode: 26   score: 160.0   memory length: 10000   epsilon: 0.8386256316056382\n",
      "episode: 27   score: 230.0   memory length: 10000   epsilon: 0.8334755504996425\n",
      "episode: 28   score: 220.0   memory length: 10000   epsilon: 0.8279844178419349\n",
      "episode: 29   score: 190.0   memory length: 10000   epsilon: 0.8226117195259973\n",
      "episode: 30   score: 130.0   memory length: 10000   epsilon: 0.8174455304448691\n",
      "episode: 31   score: 340.0   memory length: 10000   epsilon: 0.8111915634739838\n",
      "episode: 32   score: 220.0   memory length: 10000   epsilon: 0.8063228354932194\n",
      "episode: 33   score: 230.0   memory length: 10000   epsilon: 0.7991384084620816\n",
      "episode: 34   score: 100.0   memory length: 10000   epsilon: 0.7947710855413015\n",
      "episode: 35   score: 250.0   memory length: 10000   epsilon: 0.7893533739240167\n",
      "episode: 36   score: 210.0   memory length: 10000   epsilon: 0.7834945133481634\n",
      "episode: 37   score: 80.0   memory length: 10000   epsilon: 0.7792906104855207\n",
      "episode: 38   score: 140.0   memory length: 10000   epsilon: 0.7757296026172521\n",
      "episode: 39   score: 280.0   memory length: 10000   epsilon: 0.7681645440193023\n",
      "episode: 40   score: 150.0   memory length: 10000   epsilon: 0.7642645010197116\n",
      "episode: 41   score: 300.0   memory length: 10000   epsilon: 0.7594191790232289\n",
      "episode: 42   score: 230.0   memory length: 10000   epsilon: 0.7544234913669078\n",
      "episode: 43   score: 240.0   memory length: 10000   epsilon: 0.7489886529655949\n",
      "episode: 44   score: 160.0   memory length: 10000   epsilon: 0.7435111757985895\n",
      "episode: 45   score: 170.0   memory length: 10000   epsilon: 0.7392556254853695\n",
      "episode: 46   score: 230.0   memory length: 10000   epsilon: 0.735237621243439\n",
      "episode: 47   score: 210.0   memory length: 10000   epsilon: 0.7308539984458382\n",
      "episode: 48   score: 230.0   memory length: 10000   epsilon: 0.7256615166695874\n",
      "episode: 49   score: 330.0   memory length: 10000   epsilon: 0.720477105995754\n",
      "episode: 50   score: 2110.0   memory length: 10000   epsilon: 0.7103185765543977\n",
      "episode: 51   score: 310.0   memory length: 10000   epsilon: 0.705391899352931\n",
      "episode: 52   score: 340.0   memory length: 10000   epsilon: 0.7000652157576659\n",
      "episode: 53   score: 300.0   memory length: 10000   epsilon: 0.6956964740914832\n",
      "episode: 54   score: 330.0   memory length: 10000   epsilon: 0.6915900973011249\n",
      "episode: 55   score: 300.0   memory length: 10000   epsilon: 0.6872261366724332\n",
      "episode: 56   score: 590.0   memory length: 10000   epsilon: 0.6800955828936882\n",
      "episode: 57   score: 230.0   memory length: 10000   epsilon: 0.6750206708740999\n",
      "episode: 58   score: 270.0   memory length: 10000   epsilon: 0.6711705552144105\n",
      "episode: 59   score: 310.0   memory length: 10000   epsilon: 0.6665420648766475\n",
      "episode: 60   score: 300.0   memory length: 10000   epsilon: 0.6621970816295301\n",
      "episode: 61   score: 140.0   memory length: 10000   epsilon: 0.6587164650864423\n",
      "episode: 62   score: 350.0   memory length: 10000   epsilon: 0.6541607765643929\n",
      "episode: 63   score: 190.0   memory length: 10000   epsilon: 0.6509697228966929\n",
      "episode: 64   score: 260.0   memory length: 10000   epsilon: 0.6467262509698456\n",
      "episode: 65   score: 320.0   memory length: 10000   epsilon: 0.6412587601019369\n",
      "episode: 66   score: 220.0   memory length: 10000   epsilon: 0.6377287458987416\n",
      "episode: 67   score: 200.0   memory length: 10000   epsilon: 0.6341801116506758\n",
      "episode: 68   score: 130.0   memory length: 10000   epsilon: 0.6305188002227903\n",
      "episode: 69   score: 200.0   memory length: 10000   epsilon: 0.6270855317594314\n",
      "episode: 70   score: 160.0   memory length: 10000   epsilon: 0.6246071710547835\n",
      "episode: 71   score: 310.0   memory length: 10000   epsilon: 0.6214546256727304\n",
      "episode: 72   score: 380.0   memory length: 10000   epsilon: 0.6159543514928227\n",
      "episode: 73   score: 270.0   memory length: 10000   epsilon: 0.6127903251235818\n",
      "episode: 74   score: 240.0   memory length: 10000   epsilon: 0.6092159490933219\n",
      "episode: 75   score: 720.0   memory length: 10000   epsilon: 0.6035764767623529\n",
      "episode: 76   score: 630.0   memory length: 10000   epsilon: 0.5973616463801079\n",
      "episode: 77   score: 430.0   memory length: 10000   epsilon: 0.5900413629674843\n",
      "episode: 78   score: 420.0   memory length: 10000   epsilon: 0.5850706439714903\n",
      "episode: 79   score: 620.0   memory length: 10000   epsilon: 0.579648886609365\n",
      "episode: 80   score: 430.0   memory length: 10000   epsilon: 0.5745473469712521\n",
      "episode: 81   score: 500.0   memory length: 10000   epsilon: 0.5692914185553979\n",
      "episode: 82   score: 380.0   memory length: 10000   epsilon: 0.5645180848803669\n",
      "episode: 83   score: 300.0   memory length: 10000   epsilon: 0.5594601914881288\n",
      "episode: 84   score: 160.0   memory length: 10000   epsilon: 0.5559188572015266\n",
      "episode: 85   score: 310.0   memory length: 10000   epsilon: 0.5510261675904443\n",
      "episode: 86   score: 500.0   memory length: 10000   epsilon: 0.5460727747575593\n",
      "episode: 87   score: 640.0   memory length: 10000   epsilon: 0.541131440915181\n",
      "episode: 88   score: 560.0   memory length: 10000   epsilon: 0.5360578913101418\n",
      "episode: 89   score: 480.0   memory length: 10000   epsilon: 0.5314143929450983\n",
      "episode: 90   score: 720.0   memory length: 10000   epsilon: 0.527591379598501\n",
      "episode: 91   score: 370.0   memory length: 10000   epsilon: 0.5229846103753759\n",
      "episode: 92   score: 470.0   memory length: 10000   epsilon: 0.5174029567224373\n",
      "episode: 93   score: 200.0   memory length: 10000   epsilon: 0.5132494293247767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 94   score: 250.0   memory length: 10000   epsilon: 0.5094602882135263\n",
      "episode: 95   score: 440.0   memory length: 10000   epsilon: 0.506225324301613\n",
      "episode: 96   score: 600.0   memory length: 10000   epsilon: 0.5012333823048823\n",
      "episode: 97   score: 170.0   memory length: 10000   epsilon: 0.4990577416627704\n",
      "episode: 98   score: 1860.0   memory length: 10000   epsilon: 0.4942550875446346\n",
      "episode: 99   score: 770.0   memory length: 10000   epsilon: 0.48959656150890807\n",
      "episode: 100   score: 450.0   memory length: 10000   epsilon: 0.4850935029343463\n",
      "episode: 101   score: 520.0   memory length: 10000   epsilon: 0.4807856887634966\n",
      "episode: 102   score: 1050.0   memory length: 10000   epsilon: 0.4761683980394624\n",
      "episode: 103   score: 260.0   memory length: 10000   epsilon: 0.47312117374425017\n",
      "episode: 104   score: 510.0   memory length: 10000   epsilon: 0.4692245767911703\n",
      "episode: 105   score: 570.0   memory length: 10000   epsilon: 0.46482521281736955\n",
      "episode: 106   score: 120.0   memory length: 10000   epsilon: 0.46234502594352955\n",
      "episode: 107   score: 440.0   memory length: 10000   epsilon: 0.4593403273127\n",
      "episode: 108   score: 990.0   memory length: 10000   epsilon: 0.4552384484972881\n",
      "episode: 109   score: 180.0   memory length: 10000   epsilon: 0.4532533870703166\n",
      "episode: 110   score: 200.0   memory length: 10000   epsilon: 0.45115515253178945\n",
      "episode: 111   score: 3570.0   memory length: 10000   epsilon: 0.44643385429185606\n",
      "episode: 112   score: 370.0   memory length: 10000   epsilon: 0.4434349926360279\n",
      "episode: 113   score: 540.0   memory length: 10000   epsilon: 0.4398620576896651\n",
      "episode: 114   score: 930.0   memory length: 10000   epsilon: 0.43562906990805733\n",
      "episode: 115   score: 470.0   memory length: 10000   epsilon: 0.4309237110265891\n",
      "episode: 116   score: 460.0   memory length: 10000   epsilon: 0.4271567431969113\n",
      "episode: 117   score: 280.0   memory length: 10000   epsilon: 0.42422373438962724\n",
      "episode: 118   score: 780.0   memory length: 10000   epsilon: 0.4202925199648163\n",
      "episode: 119   score: 420.0   memory length: 10000   epsilon: 0.4169602548545705\n",
      "episode: 120   score: 840.0   memory length: 10000   epsilon: 0.4116694993187772\n",
      "episode: 121   score: 390.0   memory length: 10000   epsilon: 0.4085935120648887\n",
      "episode: 122   score: 950.0   memory length: 10000   epsilon: 0.40518378808253247\n",
      "episode: 123   score: 640.0   memory length: 10000   epsilon: 0.4017462696433313\n",
      "episode: 124   score: 600.0   memory length: 10000   epsilon: 0.3987404411426525\n",
      "episode: 125   score: 270.0   memory length: 10000   epsilon: 0.39565817456963115\n",
      "episode: 126   score: 600.0   memory length: 10000   epsilon: 0.39228185532445675\n",
      "episode: 127   score: 560.0   memory length: 10000   epsilon: 0.38917556291599564\n",
      "episode: 128   score: 630.0   memory length: 10000   epsilon: 0.3856385434051995\n",
      "episode: 129   score: 370.0   memory length: 10000   epsilon: 0.38261163821795036\n",
      "episode: 130   score: 400.0   memory length: 10000   epsilon: 0.38060437469569697\n",
      "episode: 131   score: 890.0   memory length: 10000   epsilon: 0.37834649124136416\n",
      "episode: 132   score: 270.0   memory length: 10000   epsilon: 0.376128330565433\n",
      "episode: 133   score: 440.0   memory length: 10000   epsilon: 0.37306413514580794\n",
      "episode: 134   score: 650.0   memory length: 10000   epsilon: 0.36945919467893695\n",
      "episode: 135   score: 510.0   memory length: 10000   epsilon: 0.3664896423896388\n",
      "episode: 136   score: 760.0   memory length: 10000   epsilon: 0.36214337625072857\n",
      "episode: 137   score: 800.0   memory length: 10000   epsilon: 0.356741034591135\n",
      "episode: 138   score: 460.0   memory length: 10000   epsilon: 0.35384893492387615\n",
      "episode: 139   score: 250.0   memory length: 10000   epsilon: 0.3522003047024395\n",
      "episode: 140   score: 260.0   memory length: 10000   epsilon: 0.3504752311023671\n",
      "episode: 141   score: 1140.0   memory length: 10000   epsilon: 0.3474914268974174\n",
      "episode: 142   score: 670.0   memory length: 10000   epsilon: 0.34467086705918126\n",
      "episode: 143   score: 330.0   memory length: 10000   epsilon: 0.3417057238065461\n",
      "episode: 144   score: 1910.0   memory length: 10000   epsilon: 0.33879657963580817\n",
      "episode: 145   score: 450.0   memory length: 10000   epsilon: 0.3356033040847377\n",
      "episode: 146   score: 480.0   memory length: 10000   epsilon: 0.33289255468138185\n",
      "episode: 147   score: 640.0   memory length: 10000   epsilon: 0.33067953888882673\n",
      "episode: 148   score: 280.0   memory length: 10000   epsilon: 0.32859622399594207\n",
      "episode: 149   score: 560.0   memory length: 10000   epsilon: 0.3255218761908413\n",
      "episode: 150   score: 440.0   memory length: 10000   epsilon: 0.3226537036295349\n",
      "episode: 151   score: 790.0   memory length: 10000   epsilon: 0.31972126759368064\n",
      "episode: 152   score: 300.0   memory length: 10000   epsilon: 0.31759581238463247\n",
      "episode: 153   score: 400.0   memory length: 10000   epsilon: 0.3156990903385987\n",
      "episode: 154   score: 520.0   memory length: 10000   epsilon: 0.31377917797403077\n",
      "episode: 155   score: 590.0   memory length: 10000   epsilon: 0.3110549050133414\n",
      "episode: 156   score: 840.0   memory length: 10000   epsilon: 0.3077443440635697\n",
      "episode: 157   score: 540.0   memory length: 10000   epsilon: 0.3047675448365238\n",
      "episode: 158   score: 500.0   memory length: 10000   epsilon: 0.3020580729115224\n",
      "episode: 159   score: 200.0   memory length: 10000   epsilon: 0.30005003976021904\n",
      "episode: 160   score: 230.0   memory length: 10000   epsilon: 0.29759372543451057\n",
      "episode: 161   score: 380.0   memory length: 10000   epsilon: 0.29520474857246454\n",
      "episode: 162   score: 90.0   memory length: 10000   epsilon: 0.29386167274377134\n",
      "episode: 163   score: 800.0   memory length: 10000   epsilon: 0.29147642128724405\n",
      "episode: 164   score: 290.0   memory length: 10000   epsilon: 0.2890151395124047\n",
      "episode: 165   score: 430.0   memory length: 10000   epsilon: 0.28679825780161583\n",
      "episode: 166   score: 230.0   memory length: 10000   epsilon: 0.2843480429516903\n",
      "episode: 167   score: 470.0   memory length: 10000   epsilon: 0.2819666916218012\n",
      "episode: 168   score: 390.0   memory length: 10000   epsilon: 0.2792867135805217\n",
      "episode: 169   score: 250.0   memory length: 10000   epsilon: 0.27668477300988076\n",
      "episode: 170   score: 790.0   memory length: 10000   epsilon: 0.27457894531978266\n",
      "episode: 171   score: 290.0   memory length: 10000   epsilon: 0.27319307812806365\n",
      "episode: 172   score: 520.0   memory length: 10000   epsilon: 0.270799514200512\n",
      "episode: 173   score: 280.0   memory length: 10000   epsilon: 0.2689320411339274\n",
      "episode: 174   score: 590.0   memory length: 10000   epsilon: 0.26694660988944774\n",
      "episode: 175   score: 340.0   memory length: 10000   epsilon: 0.265636451650128\n",
      "episode: 176   score: 590.0   memory length: 10000   epsilon: 0.26299594160360273\n",
      "episode: 177   score: 2230.0   memory length: 10000   epsilon: 0.26011362266214283\n",
      "episode: 178   score: 410.0   memory length: 10000   epsilon: 0.2578011370649917\n",
      "episode: 179   score: 270.0   memory length: 10000   epsilon: 0.256548691445691\n",
      "episode: 180   score: 620.0   memory length: 10000   epsilon: 0.25398581692783323\n",
      "episode: 181   score: 430.0   memory length: 10000   epsilon: 0.25110931685637633\n",
      "episode: 182   score: 280.0   memory length: 10000   epsilon: 0.2498843835750555\n",
      "episode: 183   score: 510.0   memory length: 10000   epsilon: 0.248158662697603\n",
      "episode: 184   score: 580.0   memory length: 10000   epsilon: 0.2461271492916394\n",
      "episode: 185   score: 1370.0   memory length: 10000   epsilon: 0.24310858800423624\n",
      "episode: 186   score: 760.0   memory length: 10000   epsilon: 0.24055726155532672\n",
      "episode: 187   score: 220.0   memory length: 10000   epsilon: 0.2391971546287497\n",
      "episode: 188   score: 1180.0   memory length: 10000   epsilon: 0.2371868161540286\n",
      "episode: 189   score: 890.0   memory length: 10000   epsilon: 0.23499354319258411\n",
      "episode: 190   score: 1170.0   memory length: 10000   epsilon: 0.23315372470263176\n",
      "episode: 191   score: 330.0   memory length: 10000   epsilon: 0.23168019873349652\n",
      "episode: 192   score: 1140.0   memory length: 10000   epsilon: 0.22975141617279796\n",
      "episode: 193   score: 470.0   memory length: 10000   epsilon: 0.22791161151316866\n",
      "episode: 194   score: 580.0   memory length: 10000   epsilon: 0.22502192033928792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 195   score: 260.0   memory length: 10000   epsilon: 0.22398471167817186\n",
      "episode: 196   score: 440.0   memory length: 10000   epsilon: 0.22229331758875745\n",
      "episode: 197   score: 1100.0   memory length: 10000   epsilon: 0.21998683596482327\n",
      "episode: 198   score: 330.0   memory length: 10000   epsilon: 0.21839113920419514\n",
      "episode: 199   score: 310.0   memory length: 10000   epsilon: 0.21705214861952873\n",
      "episode: 200   score: 400.0   memory length: 10000   epsilon: 0.21546265592109914\n",
      "episode: 201   score: 650.0   memory length: 10000   epsilon: 0.2137372728747485\n",
      "episode: 202   score: 370.0   memory length: 10000   epsilon: 0.21253305637700634\n",
      "episode: 203   score: 700.0   memory length: 10000   epsilon: 0.2108943921386594\n",
      "episode: 204   score: 380.0   memory length: 10000   epsilon: 0.20957202301104355\n",
      "episode: 205   score: 620.0   memory length: 10000   epsilon: 0.20762787583450423\n",
      "episode: 206   score: 1100.0   memory length: 10000   epsilon: 0.20540165707983662\n",
      "episode: 207   score: 730.0   memory length: 10000   epsilon: 0.2036224047373398\n",
      "episode: 208   score: 310.0   memory length: 10000   epsilon: 0.20245897893920736\n",
      "episode: 209   score: 390.0   memory length: 10000   epsilon: 0.2008437520615357\n",
      "episode: 210   score: 190.0   memory length: 10000   epsilon: 0.20001197346595156\n",
      "episode: 211   score: 590.0   memory length: 10000   epsilon: 0.19832898451769237\n",
      "episode: 212   score: 110.0   memory length: 10000   epsilon: 0.197630113940275\n",
      "episode: 213   score: 1110.0   memory length: 10000   epsilon: 0.1959514901837803\n",
      "episode: 214   score: 820.0   memory length: 10000   epsilon: 0.19451262922235737\n",
      "episode: 215   score: 240.0   memory length: 10000   epsilon: 0.193761316318867\n",
      "episode: 216   score: 360.0   memory length: 10000   epsilon: 0.19241548887211612\n",
      "episode: 217   score: 460.0   memory length: 10000   epsilon: 0.19107709848421775\n",
      "episode: 218   score: 940.0   memory length: 10000   epsilon: 0.18843760309655752\n",
      "episode: 219   score: 400.0   memory length: 10000   epsilon: 0.18729537265780183\n",
      "episode: 220   score: 570.0   memory length: 10000   epsilon: 0.1858327107495091\n",
      "episode: 221   score: 490.0   memory length: 10000   epsilon: 0.18449582386262486\n",
      "episode: 222   score: 380.0   memory length: 10000   epsilon: 0.18335548276328362\n",
      "episode: 223   score: 280.0   memory length: 10000   epsilon: 0.1824957296979007\n",
      "episode: 224   score: 660.0   memory length: 10000   epsilon: 0.1805624534792361\n",
      "episode: 225   score: 520.0   memory length: 10000   epsilon: 0.17939080390609816\n",
      "episode: 226   score: 770.0   memory length: 10000   epsilon: 0.17785820738671834\n",
      "episode: 227   score: 440.0   memory length: 10000   epsilon: 0.17669527033556426\n",
      "episode: 228   score: 320.0   memory length: 10000   epsilon: 0.1754539432923293\n",
      "episode: 229   score: 560.0   memory length: 10000   epsilon: 0.174217852462721\n",
      "episode: 230   score: 680.0   memory length: 10000   epsilon: 0.1725568062460494\n",
      "episode: 231   score: 520.0   memory length: 10000   epsilon: 0.1711681580022563\n",
      "episode: 232   score: 410.0   memory length: 10000   epsilon: 0.17006597009059454\n",
      "episode: 233   score: 720.0   memory length: 10000   epsilon: 0.16855909098111865\n",
      "episode: 234   score: 180.0   memory length: 10000   epsilon: 0.16788787681477965\n",
      "episode: 235   score: 290.0   memory length: 10000   epsilon: 0.16708895459208367\n",
      "episode: 236   score: 360.0   memory length: 10000   epsilon: 0.1661176552191121\n",
      "episode: 237   score: 330.0   memory length: 10000   epsilon: 0.1645683946641632\n",
      "episode: 238   score: 440.0   memory length: 10000   epsilon: 0.16328648221867872\n",
      "episode: 239   score: 660.0   memory length: 10000   epsilon: 0.16212476319928867\n",
      "episode: 240   score: 1220.0   memory length: 10000   epsilon: 0.1598116781068733\n",
      "episode: 241   score: 660.0   memory length: 10000   epsilon: 0.15850815914201466\n",
      "episode: 242   score: 380.0   memory length: 10000   epsilon: 0.15760880431069202\n",
      "episode: 243   score: 230.0   memory length: 10000   epsilon: 0.15671455230257397\n",
      "episode: 244   score: 640.0   memory length: 10000   epsilon: 0.15508540420968484\n",
      "episode: 245   score: 1000.0   memory length: 10000   epsilon: 0.15366669122255322\n",
      "episode: 246   score: 370.0   memory length: 10000   epsilon: 0.15278716666764502\n",
      "episode: 247   score: 230.0   memory length: 10000   epsilon: 0.15179878378575248\n",
      "episode: 248   score: 300.0   memory length: 10000   epsilon: 0.15104470129595293\n",
      "episode: 249   score: 2080.0   memory length: 10000   epsilon: 0.14919076160684017\n",
      "episode: 250   score: 680.0   memory length: 10000   epsilon: 0.1478747633600506\n",
      "episode: 251   score: 1820.0   memory length: 10000   epsilon: 0.1468873091737051\n",
      "episode: 252   score: 200.0   memory length: 10000   epsilon: 0.14621756235915437\n",
      "episode: 253   score: 720.0   memory length: 10000   epsilon: 0.1448814207294202\n",
      "episode: 254   score: 430.0   memory length: 10000   epsilon: 0.14377586320993344\n",
      "episode: 255   score: 110.0   memory length: 10000   epsilon: 0.14318901791188182\n",
      "episode: 256   score: 350.0   memory length: 10000   epsilon: 0.1424762809065842\n",
      "episode: 257   score: 310.0   memory length: 10000   epsilon: 0.14168063963015745\n",
      "episode: 258   score: 210.0   memory length: 10000   epsilon: 0.14114609506534295\n",
      "episode: 259   score: 150.0   memory length: 10000   epsilon: 0.14056014400334618\n",
      "episode: 260   score: 600.0   memory length: 10000   epsilon: 0.1394471154441009\n",
      "episode: 261   score: 700.0   memory length: 10000   epsilon: 0.13834843428008708\n",
      "episode: 262   score: 1270.0   memory length: 10000   epsilon: 0.1368650405987941\n",
      "episode: 263   score: 300.0   memory length: 10000   epsilon: 0.13606671350314667\n",
      "episode: 264   score: 500.0   memory length: 10000   epsilon: 0.1352216487626579\n",
      "episode: 265   score: 480.0   memory length: 10000   epsilon: 0.13436839485741894\n",
      "episode: 266   score: 410.0   memory length: 10000   epsilon: 0.13341108251760492\n",
      "episode: 267   score: 1260.0   memory length: 10000   epsilon: 0.13209153875682325\n",
      "episode: 268   score: 290.0   memory length: 10000   epsilon: 0.1314577008883352\n",
      "episode: 269   score: 320.0   memory length: 10000   epsilon: 0.13079812557755502\n",
      "episode: 270   score: 220.0   memory length: 10000   epsilon: 0.13009111393421338\n",
      "episode: 271   score: 660.0   memory length: 10000   epsilon: 0.12885593968055972\n",
      "episode: 272   score: 330.0   memory length: 10000   epsilon: 0.1280595003854274\n",
      "episode: 273   score: 670.0   memory length: 10000   epsilon: 0.12664209356012066\n",
      "episode: 274   score: 370.0   memory length: 10000   epsilon: 0.12586311357246704\n",
      "episode: 275   score: 370.0   memory length: 10000   epsilon: 0.12518152564377266\n",
      "episode: 276   score: 270.0   memory length: 10000   epsilon: 0.12457087917757553\n",
      "episode: 277   score: 1160.0   memory length: 10000   epsilon: 0.12320563756046729\n",
      "episode: 278   score: 190.0   memory length: 10000   epsilon: 0.12266104103503542\n",
      "episode: 279   score: 470.0   memory length: 10000   epsilon: 0.12177495998217508\n",
      "episode: 280   score: 510.0   memory length: 10000   epsilon: 0.12054157331237107\n",
      "episode: 281   score: 750.0   memory length: 10000   epsilon: 0.11920856958883858\n",
      "episode: 282   score: 950.0   memory length: 10000   epsilon: 0.11784905223507214\n",
      "episode: 283   score: 1610.0   memory length: 10000   epsilon: 0.11630016997787616\n",
      "episode: 284   score: 630.0   memory length: 10000   epsilon: 0.11531464993916926\n",
      "episode: 285   score: 640.0   memory length: 10000   epsilon: 0.11421520484613998\n",
      "episode: 286   score: 300.0   memory length: 10000   epsilon: 0.11370125153838367\n",
      "episode: 287   score: 460.0   memory length: 10000   epsilon: 0.11302673439761064\n",
      "episode: 288   score: 980.0   memory length: 10000   epsilon: 0.1117097868727483\n",
      "episode: 289   score: 410.0   memory length: 10000   epsilon: 0.11103820036824812\n",
      "episode: 290   score: 1060.0   memory length: 10000   epsilon: 0.11009616894337794\n",
      "episode: 291   score: 580.0   memory length: 10000   epsilon: 0.1092462172015071\n",
      "episode: 292   score: 1840.0   memory length: 10000   epsilon: 0.10766926156833341\n",
      "episode: 293   score: 680.0   memory length: 10000   epsilon: 0.10661072176870187\n",
      "episode: 294   score: 750.0   memory length: 10000   epsilon: 0.10576334948430607\n",
      "episode: 295   score: 290.0   memory length: 10000   epsilon: 0.10514117981683564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 296   score: 550.0   memory length: 10000   epsilon: 0.10442759732054385\n",
      "episode: 297   score: 470.0   memory length: 10000   epsilon: 0.10348161221533557\n",
      "episode: 298   score: 460.0   memory length: 10000   epsilon: 0.10257599035495302\n",
      "episode: 299   score: 710.0   memory length: 10000   epsilon: 0.10153807409355445\n",
      "episode: 300   score: 1260.0   memory length: 10000   epsilon: 0.10030682929821444\n",
      "episode: 301   score: 710.0   memory length: 10000   epsilon: 0.0993862461389948\n",
      "episode: 302   score: 530.0   memory length: 10000   epsilon: 0.09859038040813006\n",
      "episode: 303   score: 450.0   memory length: 10000   epsilon: 0.09793105018565738\n",
      "episode: 304   score: 360.0   memory length: 10000   epsilon: 0.09716918383506043\n",
      "episode: 305   score: 870.0   memory length: 10000   epsilon: 0.09627258318257431\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DQN Agent for the MsPacman\n",
    "# it uses Neural Network to approximate q function and replay memory & target q network\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see MsPacman learning, then change to True\n",
    "        self.render = True\n",
    "        self.load_model = False\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.05\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.99999\n",
    "        self.epsilon_min = 0.0\n",
    "        self.batch_size = 256\n",
    "        self.train_start = 1000\n",
    "        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        # create main model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./pacman.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self):\n",
    "\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "#         total_training_steps += batch_size\n",
    "\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0] #STATE\n",
    "            action.append(mini_batch[i][1])    #ACTION\n",
    "            reward.append(mini_batch[i][2])    #REWARD\n",
    "            update_target[i] = mini_batch[i][3]#NEXT STATE\n",
    "            done.append(mini_batch[i][4])      #DONE\n",
    "\n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.model.predict(update_target)\n",
    "\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # Q Learning: get maximum Q value at s' from model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (np.amax(target_val[i]))\n",
    "#         print(update_input, update_target)\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "        \n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from gym import wrappers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EPISODES = 1000\n",
    "    env = gym.make('MsPacman-ram-v0')\n",
    "    env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "    \n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        lives = 3\n",
    "        while not done: \n",
    "            dead = False         \n",
    "            while not dead:\n",
    "                if agent.render:\n",
    "                    env.render()\n",
    "\n",
    "                # get action for the current state and go one step in environment\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                reward = reward if not dead else -1000  # if action make Pacman dead, then gives penalty of -100\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "                \n",
    "               \n",
    "                \n",
    "                \n",
    "                # save the sample <s, a, r, s'> to the replay memory\n",
    "                agent.append_sample(state, action, reward, next_state, done)\n",
    "                \n",
    "                # every time step do the training\n",
    "                agent.train_model()\n",
    "\n",
    "                state = next_state            \n",
    "                score += reward\n",
    "                dead = info['ale.lives'] < lives\n",
    "                lives = info['ale.lives']\n",
    "                \n",
    "\n",
    "\n",
    "            if done:\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./pacman.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "    #         # save the model\n",
    "        if e % 20 == 0:\n",
    "            agent.model.save_weights(\"./pacman_correctedv3.h5\")\n",
    "\n",
    "#     print(\"Total Training Steps: {}\".format(total_training_steps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINDING\n",
    "\n",
    "The Pacman learns to just stay in the corner after consuming the \"Power Pellets\" since the reward from consuming ghosts outweight the negative reward of dying. Must increase the negative reward from dying.\n",
    "\n",
    "The learned weights will be in 'correctedv1.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Test Trained Weights- No Training Involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 25,353\n",
      "Trainable params: 25,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DQN Agent for the MsPacman\n",
    "# it uses Neural Network to approximate q function and replay memory & target q network\n",
    "class TEST_DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see MsPacman learning, then change to True\n",
    "        self.render = True\n",
    "        self.load_model = True\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # create main model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./pacman_correctedv3.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam())\n",
    "        return model\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        q_value = self.model.predict(state)\n",
    "        return np.argmax(q_value[0])\n",
    "        \n",
    "        \n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from gym import wrappers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EPISODES = 10\n",
    "    ALL_SCORES = np.zeros(EPISODES)\n",
    "\n",
    "    env = gym.make('MsPacman-ram-v0')\n",
    "    env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = TEST_DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        lives = 3\n",
    "        while not done: \n",
    "            dead = False         \n",
    "            while not dead:\n",
    "                if agent.render:\n",
    "                    env.render()\n",
    "\n",
    "                # get action for the current state and go one step in environment\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "                state = next_state            \n",
    "                score += reward\n",
    "                dead = info['ale.lives']<lives\n",
    "                lives = info['ale.lives']\n",
    "                # if an action make the Pacman dead, then gives penalty of -100\n",
    "                reward = reward if not dead else -500\n",
    "\n",
    "            if done:\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./pacman.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score)\n",
    "        \n",
    "        ALL_SCORES[e] = score\n",
    "                \n",
    "    env.close()\n",
    "    plt.plot(ALL_SCORES)\n",
    "    plt.title(\"Random Agent: {} Episodes\".format(EPISODES))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-------------------------\")\n",
    "    print('Average Score for {} Episodes: {}'.format(EPISODES, np.mean(ALL_SCORES)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
