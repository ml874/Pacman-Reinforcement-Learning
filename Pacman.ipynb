{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 150.0\n",
      "Total Score: 340.0\n",
      "Total Score: 110.0\n",
      "Total Score: 260.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 130.0\n",
      "Total Score: 350.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 270.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 290.0\n",
      "Total Score: 220.0\n",
      "Total Score: 270.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 290.0\n",
      "Total Score: 240.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 280.0\n",
      "Total Score: 120.0\n",
      "Total Score: 180.0\n",
      "Total Score: 140.0\n",
      "Total Score: 150.0\n",
      "Total Score: 210.0\n",
      "Total Score: 120.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 310.0\n",
      "Total Score: 410.0\n",
      "Total Score: 280.0\n",
      "Total Score: 120.0\n",
      "Total Score: 200.0\n",
      "Total Score: 140.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 340.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 300.0\n",
      "Total Score: 190.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 270.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n",
      "Total Score: 230.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 200.0\n",
      "Total Score: 170.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 140.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 410.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 410.0\n",
      "Total Score: 220.0\n",
      "Total Score: 110.0\n",
      "Total Score: 330.0\n",
      "Total Score: 260.0\n",
      "Total Score: 90.0\n",
      "Total Score: 260.0\n",
      "Total Score: 290.0\n",
      "Total Score: 170.0\n",
      "Total Score: 120.0\n",
      "Total Score: 290.0\n",
      "Total Score: 210.0\n",
      "Total Score: 130.0\n",
      "Total Score: 140.0\n",
      "Total Score: 220.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 350.0\n",
      "Total Score: 190.0\n",
      "Total Score: 280.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 180.0\n",
      "Total Score: 270.0\n",
      "Total Score: 100.0\n",
      "Total Score: 160.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 350.0\n",
      "Total Score: 100.0\n",
      "Total Score: 330.0\n",
      "Total Score: 160.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 160.0\n",
      "Total Score: 100.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 240.0\n",
      "Total Score: 300.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 110.0\n",
      "Total Score: 110.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 130.0\n",
      "Total Score: 190.0\n",
      "Total Score: 160.0\n",
      "Total Score: 230.0\n",
      "Total Score: 130.0\n",
      "Total Score: 260.0\n",
      "Total Score: 280.0\n",
      "Total Score: 110.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 260.0\n",
      "Total Score: 150.0\n",
      "Total Score: 400.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 250.0\n",
      "Total Score: 320.0\n",
      "Total Score: 370.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 270.0\n",
      "Total Score: 410.0\n",
      "Total Score: 250.0\n",
      "Total Score: 170.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 140.0\n",
      "Total Score: 140.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 350.0\n",
      "Total Score: 170.0\n",
      "Total Score: 190.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 170.0\n",
      "Total Score: 290.0\n",
      "Total Score: 540.0\n",
      "Total Score: 290.0\n",
      "Total Score: 310.0\n",
      "Total Score: 280.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 270.0\n",
      "Total Score: 340.0\n",
      "Total Score: 230.0\n",
      "Total Score: 110.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 270.0\n",
      "Total Score: 320.0\n",
      "Total Score: 140.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 290.0\n",
      "Total Score: 420.0\n",
      "Total Score: 130.0\n",
      "Total Score: 170.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 340.0\n",
      "Total Score: 190.0\n",
      "Total Score: 110.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 120.0\n",
      "Total Score: 230.0\n",
      "Total Score: 190.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 350.0\n",
      "Total Score: 200.0\n",
      "Total Score: 150.0\n",
      "Total Score: 160.0\n",
      "Total Score: 110.0\n",
      "Total Score: 280.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 140.0\n",
      "Total Score: 280.0\n",
      "Total Score: 300.0\n",
      "Total Score: 190.0\n",
      "Total Score: 230.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 110.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 240.0\n",
      "Total Score: 130.0\n",
      "Total Score: 220.0\n",
      "Total Score: 300.0\n",
      "Total Score: 270.0\n",
      "Total Score: 290.0\n",
      "Total Score: 160.0\n",
      "Total Score: 130.0\n",
      "Total Score: 220.0\n",
      "Total Score: 150.0\n",
      "Total Score: 300.0\n",
      "Total Score: 160.0\n",
      "Total Score: 300.0\n",
      "Total Score: 160.0\n",
      "Total Score: 260.0\n",
      "Total Score: 970.0\n",
      "Total Score: 270.0\n",
      "Total Score: 100.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 260.0\n",
      "Total Score: 170.0\n",
      "Total Score: 200.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 170.0\n",
      "Total Score: 240.0\n",
      "Total Score: 150.0\n",
      "Total Score: 130.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 610.0\n",
      "Total Score: 230.0\n",
      "Total Score: 150.0\n",
      "Total Score: 110.0\n",
      "Total Score: 160.0\n",
      "Total Score: 150.0\n",
      "Total Score: 200.0\n",
      "Total Score: 260.0\n",
      "Total Score: 200.0\n",
      "Total Score: 220.0\n",
      "Total Score: 220.0\n",
      "Total Score: 260.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 170.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 180.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 240.0\n",
      "Total Score: 150.0\n",
      "Total Score: 260.0\n",
      "Total Score: 260.0\n",
      "Total Score: 200.0\n",
      "Total Score: 270.0\n",
      "Total Score: 250.0\n",
      "Total Score: 150.0\n",
      "Total Score: 290.0\n",
      "Total Score: 130.0\n",
      "Total Score: 200.0\n",
      "Total Score: 130.0\n",
      "Total Score: 190.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 150.0\n",
      "Total Score: 310.0\n",
      "Total Score: 240.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 140.0\n",
      "Total Score: 150.0\n",
      "Total Score: 320.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 180.0\n",
      "Total Score: 290.0\n",
      "Total Score: 110.0\n",
      "Total Score: 160.0\n",
      "Total Score: 260.0\n",
      "Total Score: 210.0\n",
      "Total Score: 230.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 140.0\n",
      "Total Score: 240.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 170.0\n",
      "Total Score: 190.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 110.0\n",
      "Total Score: 270.0\n",
      "Total Score: 220.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 150.0\n",
      "Total Score: 180.0\n",
      "Total Score: 280.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 170.0\n",
      "Total Score: 210.0\n",
      "Total Score: 230.0\n",
      "Total Score: 290.0\n",
      "Total Score: 210.0\n",
      "Total Score: 250.0\n",
      "Total Score: 220.0\n",
      "Total Score: 200.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 210.0\n",
      "Total Score: 170.0\n",
      "Total Score: 150.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 150.0\n",
      "Total Score: 190.0\n",
      "Total Score: 190.0\n",
      "Total Score: 170.0\n",
      "Total Score: 340.0\n",
      "Total Score: 200.0\n",
      "Total Score: 140.0\n",
      "Total Score: 250.0\n",
      "Total Score: 70.0\n",
      "Total Score: 150.0\n",
      "Total Score: 130.0\n",
      "Total Score: 180.0\n",
      "Total Score: 260.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 150.0\n",
      "Total Score: 200.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 180.0\n",
      "Total Score: 150.0\n",
      "Total Score: 240.0\n",
      "Total Score: 170.0\n",
      "Total Score: 270.0\n",
      "Total Score: 320.0\n",
      "Total Score: 210.0\n",
      "Total Score: 110.0\n",
      "Total Score: 240.0\n",
      "Total Score: 580.0\n",
      "Total Score: 170.0\n",
      "Total Score: 220.0\n",
      "Total Score: 160.0\n",
      "Total Score: 120.0\n",
      "Total Score: 210.0\n",
      "Total Score: 160.0\n",
      "Total Score: 200.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 380.0\n",
      "Total Score: 200.0\n",
      "Total Score: 250.0\n",
      "Total Score: 210.0\n",
      "Total Score: 160.0\n",
      "Total Score: 190.0\n",
      "Total Score: 140.0\n",
      "Total Score: 300.0\n",
      "Total Score: 230.0\n",
      "Total Score: 160.0\n",
      "Total Score: 270.0\n",
      "Total Score: 120.0\n",
      "Total Score: 340.0\n",
      "Total Score: 190.0\n",
      "Total Score: 160.0\n",
      "Total Score: 210.0\n",
      "Total Score: 240.0\n",
      "Total Score: 260.0\n",
      "Total Score: 290.0\n",
      "Total Score: 230.0\n",
      "Total Score: 250.0\n",
      "Total Score: 290.0\n",
      "Total Score: 170.0\n",
      "Total Score: 290.0\n",
      "Total Score: 100.0\n",
      "Total Score: 330.0\n",
      "Total Score: 240.0\n",
      "Total Score: 270.0\n",
      "Total Score: 190.0\n",
      "Total Score: 150.0\n",
      "Total Score: 320.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 130.0\n",
      "Total Score: 200.0\n",
      "Total Score: 200.0\n",
      "Total Score: 160.0\n",
      "Total Score: 240.0\n",
      "Total Score: 230.0\n",
      "Total Score: 230.0\n",
      "Total Score: 180.0\n",
      "Total Score: 250.0\n",
      "Total Score: 320.0\n",
      "Total Score: 320.0\n",
      "Total Score: 280.0\n",
      "Total Score: 240.0\n",
      "Total Score: 160.0\n",
      "Total Score: 220.0\n",
      "Total Score: 170.0\n",
      "Total Score: 230.0\n",
      "Total Score: 210.0\n",
      "Total Score: 210.0\n",
      "Total Score: 60.0\n",
      "Total Score: 250.0\n",
      "Total Score: 240.0\n",
      "Total Score: 310.0\n",
      "Total Score: 180.0\n",
      "Total Score: 280.0\n",
      "Total Score: 210.0\n",
      "Total Score: 310.0\n",
      "Total Score: 210.0\n",
      "Total Score: 220.0\n",
      "Total Score: 210.0\n",
      "Total Score: 190.0\n",
      "Total Score: 220.0\n",
      "Total Score: 240.0\n",
      "Total Score: 240.0\n",
      "Total Score: 200.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Average Score for 500 Episodes: 214.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import wrappers, logger\n",
    "\n",
    "\n",
    "EPISODES = 500\n",
    "ALL_SCORES = np.zeros(EPISODES)\n",
    "\n",
    "env = gym.make(\"MsPacman-ram-v0\")\n",
    "env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    env.reset()\n",
    "    \n",
    "    reward, info, done = None, None, None\n",
    "\n",
    "    \n",
    "    total_score = 0\n",
    "    while done != True:\n",
    "        # env.render()\n",
    "        random_action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(random_action)\n",
    "        total_score += reward\n",
    "    ALL_SCORES[episode] = total_score\n",
    "    print(\"Total Score: {}\".format(total_score))\n",
    "    # print(state, reward, done, info)\n",
    "    \n",
    "env.close()\n",
    "plt.plot(ALL_SCORES)\n",
    "plt.title(\"Random Agent: {} Episodes\".format(EPISODES))\n",
    "plt.show()\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print('Average Score for {} Episodes: {}'.format(EPISODES, np.mean(ALL_SCORES)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2- corrected reward (0.01 LR, batch size 256, min epsilon 0.05, episilon decay 0.9999)  \n",
    "v2- corrected reward (0.05 LR, batch size 256, min epsilon 0.0, episilon decay 0.99999), increased memeory from 2000 to 10000\n",
    "\n",
    "BOTH STILL GET STUCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 25,353\n",
      "Trainable params: 25,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 230.0   memory length: 719   epsilon: 0.9928357505193836\n",
      "episode: 1   score: 170.0   memory length: 1395   epsilon: 0.9861467815885813\n",
      "episode: 2   score: 140.0   memory length: 1863   epsilon: 0.9815423743456438\n",
      "episode: 3   score: 140.0   memory length: 2551   epsilon: 0.9748125064526317\n",
      "episode: 4   score: 180.0   memory length: 3130   epsilon: 0.9691846223478606\n",
      "episode: 5   score: 980.0   memory length: 4109   epsilon: 0.9597425520330287\n",
      "episode: 6   score: 170.0   memory length: 4715   epsilon: 0.9539440703200388\n",
      "episode: 7   score: 230.0   memory length: 5389   epsilon: 0.9475360744505841\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed72f42ca12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;31m# get action for the current state and go one step in environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleImageViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_meanings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mblit\u001b[0;34m(self, x, y, z, width, height)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_texture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblit_to_texture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternalformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mget_texture\u001b[0;34m(self, rectangle, force_rectangle)\u001b[0m\n\u001b[1;32m    816\u001b[0m             self._current_texture = self.create_texture(Texture, \n\u001b[1;32m    817\u001b[0m                                                         \u001b[0mrectangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m                                                         force_rectangle)\n\u001b[0m\u001b[1;32m    819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_texture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mcreate_texture\u001b[0;34m(self, cls, rectangle, force_rectangle)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0minternalformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_internalformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         texture = cls.create(self.width, self.height, internalformat, \n\u001b[0;32m--> 803\u001b[0;31m                              rectangle, force_rectangle)\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_x\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mtexture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyglet/image/__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, width, height, internalformat, rectangle, force_rectangle, min_filter, mag_filter)\u001b[0m\n\u001b[1;32m   1512\u001b[0m                      \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                      \u001b[0mGL_RGBA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGL_UNSIGNED_BYTE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m                      blank)\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0mtexture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexture_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexture_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# DQN Agent for the MsPacman\n",
    "# it uses Neural Network to approximate q function and replay memory & target q network\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see MsPacman learning, then change to True\n",
    "        self.render = True\n",
    "        self.load_model = False\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.05\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.99999\n",
    "        self.epsilon_min = 0.0\n",
    "        self.batch_size = 256\n",
    "        self.train_start = 1000\n",
    "        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=10000)\n",
    "\n",
    "        # create main model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./pacman.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self):\n",
    "\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "#         total_training_steps += batch_size\n",
    "\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0] #STATE\n",
    "            action.append(mini_batch[i][1])    #ACTION\n",
    "            reward.append(mini_batch[i][2])    #REWARD\n",
    "            update_target[i] = mini_batch[i][3]#NEXT STATE\n",
    "            done.append(mini_batch[i][4])      #DONE\n",
    "\n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.model.predict(update_target)\n",
    "\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # Q Learning: get maximum Q value at s' from model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (np.amax(target_val[i]))\n",
    "#         print(update_input, update_target)\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "        \n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from gym import wrappers\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EPISODES = 1000\n",
    "    env = gym.make('MsPacman-ram-v0')\n",
    "    env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "    \n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        lives = 3\n",
    "        while not done: \n",
    "            dead = False         \n",
    "            while not dead:\n",
    "                if agent.render:\n",
    "                    env.render()\n",
    "\n",
    "                # get action for the current state and go one step in environment\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                reward = reward if not dead else -1000  # if action make Pacman dead, then gives penalty of -100\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "                \n",
    "               \n",
    "                \n",
    "                \n",
    "                # save the sample <s, a, r, s'> to the replay memory\n",
    "                agent.append_sample(state, action, reward, next_state, done)\n",
    "                \n",
    "                # every time step do the training\n",
    "                agent.train_model()\n",
    "\n",
    "                state = next_state            \n",
    "                score += reward\n",
    "                dead = info['ale.lives'] < lives\n",
    "                lives = info['ale.lives']\n",
    "                \n",
    "\n",
    "\n",
    "            if done:\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./pacman.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "    #         # save the model\n",
    "        if e % 20 == 0:\n",
    "            agent.model.save_weights(\"./pacman_correctedv10.h5\")\n",
    "\n",
    "#     print(\"Total Training Steps: {}\".format(total_training_steps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINDING\n",
    "\n",
    "The Pacman learns to just stay in the corner after consuming the \"Power Pellets\" since the reward from consuming ghosts outweight the negative reward of dying. Must increase the negative reward from dying.\n",
    "\n",
    "The learned weights will be in 'correctedv1.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Test Trained Weights- No Training Involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 25,353\n",
      "Trainable params: 25,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 240.0\n",
      "episode: 1   score: 290.0\n",
      "episode: 2   score: 330.0\n",
      "episode: 3   score: 290.0\n",
      "episode: 4   score: 240.0\n",
      "episode: 5   score: 440.0\n",
      "episode: 6   score: 330.0\n",
      "episode: 7   score: 3240.0\n",
      "episode: 8   score: 240.0\n",
      "episode: 9   score: 520.0\n",
      "episode: 10   score: 450.0\n",
      "episode: 11   score: 840.0\n",
      "episode: 12   score: 520.0\n",
      "episode: 13   score: 840.0\n",
      "episode: 14   score: 240.0\n",
      "episode: 15   score: 250.0\n",
      "episode: 16   score: 300.0\n",
      "episode: 17   score: 440.0\n",
      "episode: 18   score: 890.0\n",
      "episode: 19   score: 400.0\n",
      "episode: 20   score: 290.0\n",
      "episode: 21   score: 250.0\n",
      "episode: 22   score: 530.0\n",
      "episode: 23   score: 840.0\n",
      "episode: 24   score: 460.0\n",
      "episode: 25   score: 240.0\n",
      "episode: 26   score: 440.0\n",
      "episode: 27   score: 260.0\n",
      "episode: 28   score: 240.0\n",
      "episode: 29   score: 250.0\n",
      "episode: 30   score: 440.0\n",
      "episode: 31   score: 240.0\n",
      "episode: 32   score: 320.0\n",
      "episode: 33   score: 250.0\n",
      "episode: 34   score: 440.0\n",
      "episode: 35   score: 250.0\n",
      "episode: 36   score: 450.0\n",
      "episode: 37   score: 440.0\n",
      "episode: 38   score: 250.0\n",
      "episode: 39   score: 250.0\n",
      "episode: 40   score: 440.0\n",
      "episode: 41   score: 250.0\n",
      "episode: 42   score: 250.0\n",
      "episode: 43   score: 450.0\n",
      "episode: 44   score: 500.0\n",
      "episode: 45   score: 450.0\n",
      "episode: 46   score: 240.0\n",
      "episode: 47   score: 240.0\n",
      "episode: 48   score: 500.0\n",
      "episode: 49   score: 440.0\n",
      "episode: 50   score: 250.0\n",
      "episode: 51   score: 840.0\n",
      "episode: 52   score: 520.0\n",
      "episode: 53   score: 460.0\n",
      "episode: 54   score: 850.0\n",
      "episode: 55   score: 250.0\n",
      "episode: 56   score: 920.0\n",
      "episode: 57   score: 240.0\n",
      "episode: 58   score: 250.0\n",
      "episode: 59   score: 450.0\n",
      "episode: 60   score: 250.0\n",
      "episode: 61   score: 240.0\n",
      "episode: 62   score: 320.0\n",
      "episode: 63   score: 240.0\n",
      "episode: 64   score: 250.0\n",
      "episode: 65   score: 440.0\n",
      "episode: 66   score: 240.0\n",
      "episode: 67   score: 300.0\n",
      "episode: 68   score: 440.0\n",
      "episode: 69   score: 490.0\n",
      "episode: 70   score: 250.0\n",
      "episode: 71   score: 1640.0\n",
      "episode: 72   score: 250.0\n",
      "episode: 73   score: 250.0\n",
      "episode: 74   score: 330.0\n",
      "episode: 75   score: 250.0\n",
      "episode: 76   score: 240.0\n",
      "episode: 77   score: 240.0\n",
      "episode: 78   score: 240.0\n",
      "episode: 79   score: 330.0\n",
      "episode: 80   score: 240.0\n",
      "episode: 81   score: 440.0\n",
      "episode: 82   score: 250.0\n",
      "episode: 83   score: 280.0\n",
      "episode: 84   score: 440.0\n",
      "episode: 85   score: 290.0\n",
      "episode: 86   score: 290.0\n",
      "episode: 87   score: 440.0\n",
      "episode: 88   score: 440.0\n",
      "episode: 89   score: 330.0\n",
      "episode: 90   score: 920.0\n",
      "episode: 91   score: 440.0\n",
      "episode: 92   score: 240.0\n",
      "episode: 93   score: 440.0\n",
      "episode: 94   score: 250.0\n",
      "episode: 95   score: 440.0\n",
      "episode: 96   score: 320.0\n",
      "episode: 97   score: 320.0\n",
      "episode: 98   score: 250.0\n",
      "episode: 99   score: 450.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Average Score for 100 Episodes: 419.9\n"
     ]
    }
   ],
   "source": [
    "# DQN Agent for the MsPacman\n",
    "# it uses Neural Network to approximate q function and replay memory & target q network\n",
    "class TEST_DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see MsPacman learning, then change to True\n",
    "        self.render = True\n",
    "        self.load_model = True\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # create main model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./pacman_correctedv3.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam())\n",
    "        return model\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "#         q_value = self.model.predict(state)\n",
    "#         return np.argmax(q_value[0])\n",
    "        \n",
    "        \n",
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from gym import wrappers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EPISODES = 100\n",
    "    ALL_SCORES = np.zeros(EPISODES)\n",
    "\n",
    "    env = gym.make('MsPacman-ram-v0')\n",
    "    env = wrappers.Monitor(env, '/tmp/MsPacman-ram-experiment-1',force=True)\n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = TEST_DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        lives = 3\n",
    "        while not done: \n",
    "            dead = False         \n",
    "            while not dead:\n",
    "                if agent.render:\n",
    "                    env.render()\n",
    "\n",
    "                # get action for the current state and go one step in environment\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "                state = next_state            \n",
    "                score += reward\n",
    "                dead = info['ale.lives']<lives\n",
    "                lives = info['ale.lives']\n",
    "                # if an action make the Pacman dead, then gives penalty of -100\n",
    "                reward = reward if not dead else -500\n",
    "\n",
    "            if done:\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig(\"./pacman.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score)\n",
    "        \n",
    "        ALL_SCORES[e] = score\n",
    "                \n",
    "    env.close()\n",
    "    plt.plot(ALL_SCORES)\n",
    "    plt.title(\"Random Agent: {} Episodes\".format(EPISODES))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-------------------------\")\n",
    "    print('Average Score for {} Episodes: {}'.format(EPISODES, np.mean(ALL_SCORES)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
